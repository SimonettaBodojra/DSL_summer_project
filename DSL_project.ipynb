{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "DSL_project.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "2bQvYs-Aes9p",
    "colab_type": "text"
   },
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "7XlHUZMses9r",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "outputId": "f84ca1eb-2efb-447f-a1be-2086904e1955"
   },
   "source": [
    "import nltk\n",
    "\"\"\"nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\"\"\""
   ],
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "\"nltk.download('punkt')\\nnltk.download('stopwords')\\nnltk.download('wordnet')\\nnltk.download('words')\""
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "dncBQS9Oes9w",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "## Data Analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import clone\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Preprocessing and Feature Engineering\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as sw, stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Model Selection and Validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ],
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "loWHj0Jies90",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def save_results(path, model_name, params, accuracy_max):\n",
    "    with open(path, \"w\", encoding='utf8') as f:\n",
    "        f.write(f\"{model_name}:\\n\")\n",
    "        f.write(f\"BEST PARAMS: {params}\\n\")\n",
    "        f.write(f\"BEST ACCURACY: {accuracy_max}\")\n",
    "        \n",
    "#&&\n",
    "DEVELOPMENT = \"dataset/development.jsonl\"\n",
    "EVALUATION = \"dataset/evaluation.jsonl\"\n",
    "data_dev = pd.read_json(DEVELOPMENT, lines=True)\n",
    "data_ev = pd.read_json(EVALUATION, lines=True)"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Nph7l9-Kes93",
    "colab_type": "text"
   },
   "source": [
    "Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "C_fR92U_es97",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "ccefc9ac-a12d-4ed1-a11f-74ee928b8430"
   },
   "source": [
    "X_dev_text = data_dev.loc[:, \"full_text\"]\n",
    "y_dev_text = data_dev.loc[:, \"class\"]\n",
    "X_ev_text = data_ev.loc[:, \"full_text\"]\n",
    "\n",
    "print(f\"Training dataset size: {len(X_dev_text)}\\n\")\n",
    "print(f\"Evaluation dataset size: {len(X_ev_text)}\\n\")"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training dataset size: 80000\n",
      "\n",
      "Evaluation dataset size: 20000\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "RAAXEtEaes9_",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "outputId": "3d19fe0b-fee9-4fcb-89c9-d5bf3f101d03"
   },
   "source": [
    "X_dev_text_pos = data_dev.loc[data_dev.loc[:,\"class\"]==1,\"full_text\"]\n",
    "X_dev_text_neg = data_dev.loc[data_dev.loc[:,\"class\"]==0,\"full_text\"]\n",
    "\n",
    "print(f\"Positive dataset size: {len(X_dev_text_pos)}\\n\")\n",
    "print(f\"Negative dataset size: {len(X_dev_text_neg)}\\n\")\n",
    "\n",
    "sns.countplot(x = 'class',data = data_dev)"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Positive dataset size: 39931\n",
      "\n",
      "Negative dataset size: 40069\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x2764f46c408>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 58
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "pEMrnLg_es-C",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "c5de5acd-ec9e-4156-cab4-df0b13ee5339"
   },
   "source": [
    "rt = sum(data_dev.loc[:,\"retweeted\"]==True)\n",
    "ft = sum(data_dev.loc[:,\"favorited\"]==True)\n",
    "print(f\"Retweets = {rt} and Favorited = {ft}\")"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Retweets = 0 and Favorited = 0\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "IAYHoWYzes-I",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "3d6dc0d4-7f42-4aa4-b3d6-5d841274653a"
   },
   "source": [
    "print(X_dev_text_neg.shape[0]+X_dev_text_pos.shape[0])\n",
    "print(X_dev_text.shape[0])"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "80000\n",
      "80000\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C-RvbzrWnBeS",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "f264d65f-c439-4cec-ec61-8f78f19a6093"
   },
   "source": [
    "#pip install demoji"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "NemY9Audes-M",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "b9c493cd-bec6-4476-cfd8-71d869dd5f5d"
   },
   "source": [
    "import demoji\n",
    "import re\n",
    "#demoji.download_codes()\n",
    "example = None\n",
    "emoji_dict = {}\n",
    "hashtag_dict= {}\n",
    "\n",
    "for text in X_dev_text_pos:\n",
    "\n",
    "    text_list=text.split()\n",
    "    for word in text_list:\n",
    "      if word.startswith(\"#\"):\n",
    "        if word not in hashtag_dict:\n",
    "          hashtag_dict[word] = [1, 0]\n",
    "        else:\n",
    "          hashtag_dict[word][0] += 1\n",
    "\n",
    "    current_emojis = demoji.findall(text)\n",
    "    for emoji, desc in current_emojis.items():\n",
    "        if emoji not in emoji_dict:\n",
    "            emoji_dict[emoji] = [desc, 1, 0]\n",
    "        else:\n",
    "            emoji_dict[emoji][1] += 1\n",
    "            \n",
    "for text in X_dev_text_neg:\n",
    "    text_list=text.split()\n",
    "    for word in text_list:\n",
    "      if word.startswith(\"#\"):\n",
    "        if word not in hashtag_dict:\n",
    "          hashtag_dict[word] = [0,1]\n",
    "        else:\n",
    "          hashtag_dict[word][1] += 1\n",
    "\n",
    "    current_emojis = demoji.findall(text)\n",
    "    for emoji, desc in current_emojis.items():\n",
    "        if emoji not in emoji_dict:\n",
    "            emoji_dict[emoji] = [desc, 0, 1]\n",
    "        else:\n",
    "            emoji_dict[emoji][2] += 1"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "Asuui36ses-P",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "total = sorted(hashtag_dict.items(), key=lambda x: sum(x[1][1:]),reverse=True)\n",
    "\n",
    "with open(\"total_hashtags.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in total:\n",
    "        f.write(f\"{e}\\n\")    \n"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3hTcMHcS0lUm",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "total = sorted(emoji_dict.items(), key=lambda x: sum(x[1][1:]),reverse=True)\n",
    "\n",
    "with open(\"total_emojis.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in total:\n",
    "        f.write(f\"{e}\\n\")"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "w5Ei3uTUes-S",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "sentiment_emojis = {}\n",
    "\n",
    "for emoji, desc in emoji_dict.items():\n",
    "    pos_perc = emoji_dict[emoji][1]/sum(emoji_dict[emoji][1:])\n",
    "    sentiment_emojis[emoji] = pos_perc\n",
    "    "
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47AG-NvxtXxS",
    "colab_type": "text"
   },
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "195\n",
      "173\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "long_stopwords=[]\n",
    "\n",
    "STOPWORDS = \"stopwords_long.txt\"\n",
    "with open(STOPWORDS, \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        long_stopwords.append(line[:-1])\n",
    "\n",
    "stopwords=sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could','doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "print(len(stopwords))\n",
    "print(len(long_stopwords))\n",
    "\n",
    "#stopwords.extend(long_stopwords)\n",
    "\n",
    "#stopwords=list(set(stopwords))\n",
    "\n",
    "#print(len(stopwords))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "S1hjUlmdes-V",
    "colab_type": "text"
   },
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "5LVsZORSes-W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def preprocess_word(word):\n",
    "    \n",
    "    # Remove punctuation\n",
    "    word = word.strip(string.punctuation)\n",
    "    \n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    \n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    \n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    \n",
    "    return word\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    en_stopwords = sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could','doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "    # Check if word begins with an alphabet is not a char or a stopword\n",
    "    return re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) \\\n",
    "           and 3 < len(word) < 16 and word not in stopwords is not None\n",
    "\n",
    "\n",
    "def handle_emojis(tweet,th1,th2):\n",
    "    emojis = demoji.findall(tweet)\n",
    "    \n",
    "    for emoji in emojis.keys(): \n",
    "        \n",
    "        if emoji not in sentiment_emojis:\n",
    "            continue\n",
    "        perc= sentiment_emojis[emoji]\n",
    "        \n",
    "        if perc > th2:\n",
    "            tweet = tweet.replace(emoji, 'EM_POS')  #'EM_VERY_POS')\n",
    "        elif perc > th1:\n",
    "            tweet = tweet.replace(emoji, 'EM_POS')\n",
    "        elif perc < (1-th2):\n",
    "            tweet = tweet.replace(emoji, 'EM_NEG')  #'EM_VERY_NEG')\n",
    "        elif perc < (1-th1):\n",
    "            tweet = tweet.replace(emoji, 'EM_NEG')\n",
    "        else:\n",
    "            tweet = tweet.replace(emoji, '')    \n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def preprocess_tweet (tweet,th1,th2):\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', '', tweet)\n",
    "    \n",
    "    # Remove @handle\n",
    "    tweet = re.sub(r'@[\\S]+', '', tweet)\n",
    "    \n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    \n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    \n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    \n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    \n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet,th1,th2)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "class TweetTokenizer(object):\n",
    "    \n",
    "    def __init__(self,th1=0.6,th2=0.85):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.th1 = th1\n",
    "        self.th2 =th2\n",
    "        \n",
    "    def __call__(self, tweet):\n",
    "        \n",
    "        lemmas = []\n",
    "        tweet = preprocess_tweet (tweet,self.th1,self.th2)\n",
    "        \n",
    "        for t in word_tokenize(tweet):\n",
    "            \n",
    "            t = t.strip()\n",
    "            \n",
    "            t = preprocess_word(t)\n",
    "            \n",
    "            if is_valid_word(t):\n",
    "             lemma = self.lemmatizer.lemmatize(t)\n",
    "             lemmas.append(lemma)\n",
    "                \n",
    "        return lemmas\n",
    "\n",
    "\n"
   ],
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"vectorizer = TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True,\n",
    "\t\t\t\t\t\t\t  preprocessor=None, tokenizer=TweetTokenizer(th1=0.65,th2=0.85), stop_words=None, ngram_range=(1,2),\n",
    "\t\t\t\t\t\t\t  max_df=0.5, min_df=1, max_features=None)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SzHXXYgv7TRU",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "\"\"\"vectorizer = CountVectorizer(input='content', encoding='utf-8', tokenizer=TweetTokenizer(th1=0.65,th2=0.85), \n",
    "                             stop_words=None, ngram_range=(1,2), max_df=0.5, min_df=1)\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='content', encoding='utf-8', tokenizer=TweetTokenizer(th1=0.65,th2=0.85), \n",
    "                             stop_words=None, ngram_range=(1,2), max_df=0.5, min_df=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "COXcTN-hoZro",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "66d81561-4b09-4fa7-a936-82b0d34954d0",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "#Get top 10 words (REMEMBER TO CHECK IF NGRAM_RANGE=(1,1))\n",
    "\n",
    "def get_top_n_words (dataset, n=25):\n",
    "\n",
    "    vectorizer.fit(dataset)\n",
    "    bag_of_words = vectorizer.transform(dataset)\n",
    "    \n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return words_freq[:n]\n",
    "\n",
    "def get_word_counts(dataset,top_words):\n",
    "    \n",
    "    vectorizer.fit(dataset)\n",
    "    bag_of_words = vectorizer.transform(dataset)\n",
    "    \n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    \n",
    "    top_words2 = list(top_words['word'])\n",
    "    \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items() if word in top_words2]\n",
    "    new_words_freq = []\n",
    "\n",
    "    for word in top_words2:\n",
    "        i = -1\n",
    "        for j, word_freq in enumerate(words_freq):\n",
    "            if word_freq[0] == word:\n",
    "                i = j\n",
    "                break\n",
    "        if i == -1:\n",
    "            new_words_freq.append(tuple([word, 0]))\n",
    "            continue\n",
    "\n",
    "        new_words_freq.append(words_freq[i])\n",
    "\n",
    "    return new_words_freq"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot 1: Top 25 words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_words = pd.DataFrame(get_top_n_words(X_dev_text), columns=['word', 'count'])\n",
    "\n",
    "top_words_pos = pd.DataFrame(get_word_counts(X_dev_text_pos, top_words), columns=['word', 'count'])\n",
    "top_words_neg = pd.DataFrame(get_word_counts(X_dev_text_neg, top_words), columns = ['words', 'columns'])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.set_title('TOP 25 UNIGRAMS', fontsize=18, pad=25.0, alpha=0.85, weight='normal')\n",
    "\n",
    "indices = np.arange(len(top_words['count']))\n",
    "\n",
    "width = 0.25\n",
    "\t\t\n",
    "ax.bar(indices-(width/2), (top_words_pos['count']/len(X_dev_text_pos)), width, color='#00800050', edgecolor='#00800095', linewidth=0.5, label='Positive class')\n",
    "ax.bar(indices+(width/2), (top_words_neg['count']/len(X_dev_text_neg)), width, color='#80000050', edgecolor='#80000095', linewidth=0.5, label='Negative class')\n",
    "\n",
    "ax.set_xticklabels(top_words['word'])\n",
    "ax.set_xticks(indices)\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylabel('Document frequency', alpha=0.85, weight='normal', fontsize=14, labelpad=18.0)\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8cRVPnkoBao",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_ \n",
    "words_left_out = vectorizer.stop_words_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xrVGtHgqrRiZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "with open(\"vectorizer.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in vocabulary:\n",
    "        f.write(f\"{e}\\n\")   "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGNq_NaargNQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "with open(\"words_left_out.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in words_left_out:\n",
    "        f.write(f\"{e}\\n\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = train_test_split(X_dev_text, y_dev_text, shuffle=True, train_size=12000, stratify=y_dev_text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, shuffle=True, test_size=0.25, stratify=y_train)\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__C\": [.1, 1, 10, 50, 100],\n",
    "    \"tfidf__min_df\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "model = SVC(kernel=\"rbf\")\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", vectorizer),\n",
    "    (\"classifier\", model)\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring='accuracy', n_jobs=8, cv=3)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "k_II-ECFes-d",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "outputId": "aafad2c6-d7ca-4116-c6ed-20898b54fbf4"
   },
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25)\n",
    "\n",
    "params_model = {'C': [1, 10, 100]}\n",
    "#params_model = {'C': [1, 5, 10]}\n",
    "models = [LogisticRegression(n_jobs=8, **config) for config in ParameterGrid(params_model)]\n",
    "\n",
    "#models = [SVC(kernel=\"linear\", **config) for config in ParameterGrid(params_model)]\n",
    "\n",
    "pipelines = [Pipeline([\n",
    "    ('tfidf', vectorizers[0]),\n",
    "    ('classifier', model),\n",
    "]) for model in models]\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "TRAIN OVER\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25, stratify=y_dev_text)\n",
    "model = SVC(kernel=\"rbf\", C=10)\n",
    "tmp_pipe = Pipeline([\n",
    "    ('count', vectorizer),\n",
    "    ('classifier', model)\n",
    "])\n",
    "tmp_pipe.fit(X_train, y_train)\n",
    "print(\"TRAIN OVER\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "0.50085"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 70
    }
   ],
   "source": [
    "y_preds = tmp_pipe.predict(X_test)\n",
    "accuracy_score(y_test, y_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Yb0B-0T7fea",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25)\n",
    "\n",
    "model = SVC(kernel=\"rbf\", C=10)\n",
    "\n",
    "pipelines = Pipeline([\n",
    "    ('count', vectorizer),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', model)])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "zjP8WsEles-g",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "outputId": "99f9c778-572f-40e3-d7c3-e93e49302388"
   },
   "source": [
    "labels_predicted = []\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    labels_predicted.append(y_pred)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "jYpnCNzDes-j",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "total_config = []\n",
    "for conf_vec in ParameterGrid(params_vect):\n",
    "    for conf_mod in ParameterGrid(params_model):\n",
    "        conf_mod.update(conf_vec)\n",
    "        total_config.append(conf_mod)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "aTjhPyvoes-m",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "accuracies = [accuracy_score(y_test, y_pred) for y_pred in labels_predicted]\n",
    "best_ind = np.argmax(accuracies)\n",
    "best_pipeline = pipelines[best_ind]\n",
    "print(classification_report(y_test, labels_predicted[best_ind]))\n",
    "print(f\"Total Accuracy score: {np.max(accuracies)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, labels_predicted[best_ind])}\")\n",
    "print(f\"SVM best params: {list(total_config[best_ind].items())}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "vVCYYMtCes-q",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "MODEL_NAME = \"Logistic-Cnan\"\n",
    "PATH = f\"results/{MODEL_NAME}-emoji-preprocess.txt\"\n",
    "save_results(PATH, MODEL_NAME, list(total_config[best_ind].items()), np.max(accuracies))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "Fz3lvlN2es-t",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "best_pipeline.fit(X_dev_text, y_dev_text)\n",
    "y_preds = best_pipeline.predict(X_ev_text)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "CgpwwgK5es-y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "with open(\"submission3.csv\", \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(\"Id,Predicted\\n\")\n",
    "    for i,y in enumerate(y_preds):\n",
    "        f.write(f\"{i},{y}\\n\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "yMY3i0TWes-1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "for c in data.columns:\n",
    "    mask = data.loc[:, c].isnull()\n",
    "    boh[c] = data.loc[mask].shape[0]\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.barplot(list(boh.keys()), list(boh.values()))\n",
    "ax.set_xticklabels(list(boh.keys()), rotation=40, ha=\"right\")\n",
    "plt.show()\n",
    "# Dropping useless columns\n",
    "cleared_dataset = data_dev.drop(columns =['id','in_reply_to_status_id','in_reply_to_user_id',\n",
    "                                      'created_at', 'truncated', 'retweeted', 'lang', \n",
    "                                      'metadata', 'favorited', 'source', 'withheld_in_countries',\n",
    "                                      'quoted_status_id', 'in_reply_to_screen_name', 'contributors'])\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}