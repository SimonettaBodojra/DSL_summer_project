{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "DSL_project.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "2bQvYs-Aes9p",
    "colab_type": "text"
   },
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "7XlHUZMses9r",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "outputId": "f84ca1eb-2efb-447f-a1be-2086904e1955"
   },
   "source": [
    "import nltk\n",
    "\"\"\"nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\"\"\""
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package words to\n[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "dncBQS9Oes9w",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "## Data Analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import clone\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Preprocessing and Feature Engineering\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as sw, stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Model Selection and Validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "loWHj0Jies90",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def save_results(path, model_name, params, accuracy_max):\n",
    "    with open(path, \"w\", encoding='utf8') as f:\n",
    "        f.write(f\"{model_name}:\\n\")\n",
    "        f.write(f\"BEST PARAMS: {params}\\n\")\n",
    "        f.write(f\"BEST ACCURACY: {accuracy_max}\")\n",
    "        \n",
    "#&&\n",
    "DEVELOPMENT = \"dataset/development.jsonl\"\n",
    "EVALUATION = \"dataset/evaluation.jsonl\"\n",
    "data_dev = pd.read_json(DEVELOPMENT, lines=True)\n",
    "data_ev = pd.read_json(EVALUATION, lines=True)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Nph7l9-Kes93",
    "colab_type": "text"
   },
   "source": [
    "Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "C_fR92U_es97",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "ccefc9ac-a12d-4ed1-a11f-74ee928b8430"
   },
   "source": [
    "X_dev_text = data_dev.loc[:, \"full_text\"]\n",
    "y_dev_text = data_dev.loc[:, \"class\"]\n",
    "X_ev_text = data_ev.loc[:, \"full_text\"]\n",
    "\n",
    "print(f\"Training dataset size: {len(X_dev_text)}\\n\")\n",
    "print(f\"Evaluation dataset size: {len(X_ev_text)}\\n\")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training dataset size: 80000\n\nEvaluation dataset size: 20000\n\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "RAAXEtEaes9_",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "outputId": "3d19fe0b-fee9-4fcb-89c9-d5bf3f101d03"
   },
   "source": [
    "X_dev_text_pos = data_dev.loc[data_dev.loc[:,\"class\"]==1,\"full_text\"]\n",
    "X_dev_text_neg = data_dev.loc[data_dev.loc[:,\"class\"]==0,\"full_text\"]\n",
    "\n",
    "print(f\"Positive dataset size: {len(X_dev_text_pos)}\\n\")\n",
    "print(f\"Negative dataset size: {len(X_dev_text_neg)}\\n\")\n",
    "\n",
    "sns.countplot(x = 'class',data = data_dev)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Positive dataset size: 39931\n\nNegative dataset size: 40069\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x2673eb2d400>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "pEMrnLg_es-C",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "c5de5acd-ec9e-4156-cab4-df0b13ee5339"
   },
   "source": [
    "rt = sum(data_dev.loc[:,\"retweeted\"]==True)\n",
    "ft = sum(data_dev.loc[:,\"favorited\"]==True)\n",
    "print(f\"Retweets = {rt} and Favorited = {ft}\")"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Retweets = 0 and Favorited = 0\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "IAYHoWYzes-I",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "3d6dc0d4-7f42-4aa4-b3d6-5d841274653a"
   },
   "source": [
    "print(X_dev_text_neg.shape[0]+X_dev_text_pos.shape[0])\n",
    "print(X_dev_text.shape[0])"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "80000\n80000\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C-RvbzrWnBeS",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "f264d65f-c439-4cec-ec61-8f78f19a6093"
   },
   "source": [
    "#pip install demoji"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading https://files.pythonhosted.org/packages/da/0b/d008f26ebbfd86d21117267e627f2f7359c76e5ecbeba08d8f631f4092c4/demoji-0.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from demoji) (49.1.0)\n",
      "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
      "Installing collected packages: colorama, demoji\n",
      "Successfully installed colorama-0.4.3 demoji-0.2.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "NemY9Audes-M",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "b9c493cd-bec6-4476-cfd8-71d869dd5f5d"
   },
   "source": [
    "import demoji\n",
    "import re\n",
    "demoji.download_codes()\n",
    "example = None\n",
    "emoji_dict = {}\n",
    "hashtag_dict= {}\n",
    "\n",
    "for text in X_dev_text_pos:\n",
    "\n",
    "    text_list=text.split()\n",
    "    for word in text_list:\n",
    "      if word.startswith(\"#\"):\n",
    "        if word not in hashtag_dict:\n",
    "          hashtag_dict[word] = [1, 0]\n",
    "        else:\n",
    "          hashtag_dict[word][0] += 1\n",
    "\n",
    "    current_emojis = demoji.findall(text)\n",
    "    for emoji, desc in current_emojis.items():\n",
    "        if emoji not in emoji_dict:\n",
    "            emoji_dict[emoji] = [desc, 1, 0]\n",
    "        else:\n",
    "            emoji_dict[emoji][1] += 1\n",
    "            \n",
    "for text in X_dev_text_neg:\n",
    "    text_list=text.split()\n",
    "    for word in text_list:\n",
    "      if word.startswith(\"#\"):\n",
    "        if word not in hashtag_dict:\n",
    "          hashtag_dict[word] = [0,1]\n",
    "        else:\n",
    "          hashtag_dict[word][1] += 1\n",
    "\n",
    "    current_emojis = demoji.findall(text)\n",
    "    for emoji, desc in current_emojis.items():\n",
    "        if emoji not in emoji_dict:\n",
    "            emoji_dict[emoji] = [desc, 0, 1]\n",
    "        else:\n",
    "            emoji_dict[emoji][2] += 1"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Downloading emoji data ...",
      "\n",
      "... OK",
      " (Got response in 1.79 seconds)",
      "\n",
      "Writing emoji data to C:\\Users\\simon\\.demoji\\codes.json ...",
      "\n",
      "... OK",
      "\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "Asuui36ses-P",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "total = sorted(hashtag_dict.items(), key=lambda x: sum(x[1][1:]),reverse=True)\n",
    "\n",
    "with open(\"total_hashtags.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in total:\n",
    "        f.write(f\"{e}\\n\")    \n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3hTcMHcS0lUm",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "total = sorted(emoji_dict.items(), key=lambda x: sum(x[1][1:]),reverse=True)\n",
    "\n",
    "with open(\"total_emojis.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in total:\n",
    "        f.write(f\"{e}\\n\")"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "w5Ei3uTUes-S",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "sentiment_emojis = {}\n",
    "\n",
    "for emoji, desc in emoji_dict.items():\n",
    "    pos_perc = emoji_dict[emoji][1]/sum(emoji_dict[emoji][1:])\n",
    "    sentiment_emojis[emoji] = pos_perc\n",
    "    "
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47AG-NvxtXxS",
    "colab_type": "text"
   },
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "195",
      "\n",
      "665",
      "\n",
      "713",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "long_stopwords=[]\n",
    "\n",
    "STOPWORDS = \"stopwords_long.txt\"\n",
    "with open(STOPWORDS, \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        long_stopwords.append(line[:-1])\n",
    "\n",
    "stopwords=sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could','doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "print(len(stopwords))\n",
    "print(len(long_stopwords))\n",
    "\n",
    "stopwords.extend(long_stopwords)\n",
    "\n",
    "new_stopwords=list(set(stopwords))\n",
    "\n",
    "print(len(new_stopwords))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "S1hjUlmdes-V",
    "colab_type": "text"
   },
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "5LVsZORSes-W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def preprocess_word(word):\n",
    "    \n",
    "    # Remove punctuation\n",
    "    word = word.strip(string.punctuation)\n",
    "    \n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    \n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    \n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    \n",
    "    return word\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    en_stopwords = sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could','doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "    # Check if word begins with an alphabet is not a char or a stopword\n",
    "    return re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) \\\n",
    "           and 3 < len(word) < 16 and word not in stopwords is not None\n",
    "\n",
    "\n",
    "def handle_emojis(tweet,th1,th2):\n",
    "    emojis = demoji.findall(tweet)\n",
    "    \n",
    "    for emoji in emojis.keys(): \n",
    "        \n",
    "        if emoji not in sentiment_emojis:\n",
    "            continue\n",
    "        perc= sentiment_emojis[emoji]\n",
    "        \n",
    "        if perc > th2:\n",
    "            tweet = tweet.replace(emoji, 'EM_POS')  #'EM_VERY_POS')\n",
    "        elif perc > th1:\n",
    "            tweet = tweet.replace(emoji, 'EM_POS')\n",
    "        elif perc < (1-th2):\n",
    "            tweet = tweet.replace(emoji, 'EM_NEG')  #'EM_VERY_NEG')\n",
    "        elif perc < (1-th1):\n",
    "            tweet = tweet.replace(emoji, 'EM_NEG')\n",
    "        else:\n",
    "            tweet = tweet.replace(emoji, '')    \n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def preprocess_tweet (tweet,th1,th2):\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', '', tweet)\n",
    "    \n",
    "    # Remove @handle\n",
    "    tweet = re.sub(r'@[\\S]+', '', tweet)\n",
    "    \n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    \n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    \n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    \n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    \n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet,th1,th2)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "class TweetTokenizer(object):\n",
    "    \n",
    "    def __init__(self,th1=0.6,th2=0.85):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.th1 = th1\n",
    "        self.th2 =th2\n",
    "        \n",
    "    def __call__(self, tweet):\n",
    "        \n",
    "        lemmas = []\n",
    "        tweet = preprocess_tweet (tweet,self.th1,self.th2)\n",
    "        \n",
    "        for t in word_tokenize(tweet):\n",
    "            \n",
    "            t = t.strip()\n",
    "            \n",
    "            t = preprocess_word(t)\n",
    "            \n",
    "            if is_valid_word(t):\n",
    "             lemma = self.lemmatizer.lemmatize(t)\n",
    "             lemmas.append(lemma)\n",
    "                \n",
    "        return lemmas"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "pjMD3h3zes-Z",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "d1f1a6f2-de8e-4874-baf7-de09770f22dc"
   },
   "source": [
    "\"\"\"vectorizer = TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True,\n",
    "\t\t\t\t\t\t\t  preprocessor=None, tokenizer=TweetTokenizer(th1=0.65,th2=0.85), stop_words=None, ngram_range=(1,2),\n",
    "\t\t\t\t\t\t\t  max_df=0.5, min_df=1, max_features=None)\"\"\""
   ],
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "\"vectorizer = TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True,\\n\\t\\t\\t\\t\\t\\t\\t  preprocessor=None, tokenizer=TweetTokenizer(th1=0.65,th2=0.85), stop_words=None, ngram_range=(1,2),\\n\\t\\t\\t\\t\\t\\t\\t  max_df=0.5, min_df=1, max_features=None)\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 64
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SzHXXYgv7TRU",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "\"\"\"vectorizer = CountVectorizer(input='content', encoding='utf-8', tokenizer=TweetTokenizer(th1=0.65,th2=0.85), \n",
    "                             stop_words=None, ngram_range=(1,2), max_df=0.5, min_df=1)\"\"\""
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='content', encoding='utf-8', tokenizer=TweetTokenizer(th1=0.65,th2=0.85), \n",
    "                             stop_words=None, ngram_range=(1,2), max_df=0.5, min_df=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "COXcTN-hoZro",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "66d81561-4b09-4fa7-a936-82b0d34954d0",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "vectorizer.fit(X_dev_text)\n",
    "X_train_tfidf = vectorizer.transform(X_dev_text)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e8cRVPnkoBao",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "vocabulary = vectorizer.vocabulary_ \n",
    "words_left_out = vectorizer.stop_words_"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xrVGtHgqrRiZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "with open(\"vectorizer.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in vocabulary:\n",
    "        f.write(f\"{e}\\n\")   "
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGNq_NaargNQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "with open(\"words_left_out.txt\", \"w\", encoding='utf8') as f:\n",
    "    for e in words_left_out:\n",
    "        f.write(f\"{e}\\n\")"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "k_II-ECFes-d",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "outputId": "aafad2c6-d7ca-4116-c6ed-20898b54fbf4"
   },
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25)\n",
    "\n",
    "params_model = {'C': [1, 10, 100]}\n",
    "#params_model = {'C': [1, 5, 10]}\n",
    "models = [LogisticRegression(n_jobs=8, **config) for config in ParameterGrid(params_model)]\n",
    "\n",
    "#models = [SVC(kernel=\"linear\", **config) for config in ParameterGrid(params_model)]\n",
    "\n",
    "pipelines = [Pipeline([\n",
    "    ('tfidf', vectorizers[0]),\n",
    "    ('classifier', model),\n",
    "]) for model in models]\"\"\""
   ],
   "execution_count": 70,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25)\\n\\nparams_model = {\\'C\\': [1, 10, 100]}\\n#params_model = {\\'C\\': [1, 5, 10]}\\nmodels = [LogisticRegression(n_jobs=8, **config) for config in ParameterGrid(params_model)]\\n\\n#models = [SVC(kernel=\"linear\", **config) for config in ParameterGrid(params_model)]\\n\\npipelines = [Pipeline([\\n    (\\'tfidf\\', vectorizers[0]),\\n    (\\'classifier\\', model),\\n]) for model in models]'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 70
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "TRAIN OVER",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25, stratify=y_dev_text)\n",
    "model = SVC(kernel=\"rbf\", C=10)\n",
    "tmp_pipe = Pipeline([\n",
    "    ('count', vectorizer),\n",
    "    ('classifier', model)\n",
    "])\n",
    "tmp_pipe.fit(X_train, y_train)\n",
    "print(\"TRAIN OVER\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.924"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "y_preds = tmp_pipe.predict(X_test)\n",
    "accuracy_score(y_test, y_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Yb0B-0T7fea",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dev_text, y_dev_text, shuffle=True, test_size=0.25)\n",
    "\n",
    "model = SVC(kernel=\"rbf\", C=10)\n",
    "\n",
    "pipelines = Pipeline([\n",
    "    ('count', vectorizer),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', model)])"
   ],
   "execution_count": 95,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "zjP8WsEles-g",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "outputId": "99f9c778-572f-40e3-d7c3-e93e49302388"
   },
   "source": [
    "labels_predicted = []\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    labels_predicted.append(y_pred)"
   ],
   "execution_count": 96,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-1a8ea19b4df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'predict'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "jYpnCNzDes-j",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "total_config = []\n",
    "for conf_vec in ParameterGrid(params_vect):\n",
    "    for conf_mod in ParameterGrid(params_model):\n",
    "        conf_mod.update(conf_vec)\n",
    "        total_config.append(conf_mod)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "aTjhPyvoes-m",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "accuracies = [accuracy_score(y_test, y_pred) for y_pred in labels_predicted]\n",
    "best_ind = np.argmax(accuracies)\n",
    "best_pipeline = pipelines[best_ind]\n",
    "print(classification_report(y_test, labels_predicted[best_ind]))\n",
    "print(f\"Total Accuracy score: {np.max(accuracies)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, labels_predicted[best_ind])}\")\n",
    "print(f\"SVM best params: {list(total_config[best_ind].items())}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "vVCYYMtCes-q",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "MODEL_NAME = \"Logistic-Cnan\"\n",
    "PATH = f\"results/{MODEL_NAME}-emoji-preprocess.txt\"\n",
    "save_results(PATH, MODEL_NAME, list(total_config[best_ind].items()), np.max(accuracies))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "Fz3lvlN2es-t",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "best_pipeline.fit(X_dev_text, y_dev_text)\n",
    "y_preds = best_pipeline.predict(X_ev_text)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "CgpwwgK5es-y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "with open(\"submission3.csv\", \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(\"Id,Predicted\\n\")\n",
    "    for i,y in enumerate(y_preds):\n",
    "        f.write(f\"{i},{y}\\n\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "yMY3i0TWes-1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "'''\n",
    "for c in data.columns:\n",
    "    mask = data.loc[:, c].isnull()\n",
    "    boh[c] = data.loc[mask].shape[0]\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.barplot(list(boh.keys()), list(boh.values()))\n",
    "ax.set_xticklabels(list(boh.keys()), rotation=40, ha=\"right\")\n",
    "plt.show()\n",
    "# Dropping useless columns\n",
    "cleared_dataset = data_dev.drop(columns =['id','in_reply_to_status_id','in_reply_to_user_id',\n",
    "                                      'created_at', 'truncated', 'retweeted', 'lang', \n",
    "                                      'metadata', 'favorited', 'source', 'withheld_in_countries',\n",
    "                                      'quoted_status_id', 'in_reply_to_screen_name', 'contributors'])\n",
    "'''\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}